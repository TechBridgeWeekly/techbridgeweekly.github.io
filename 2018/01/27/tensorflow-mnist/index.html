<!DOCTYPE html>
<html>

<head><meta name="generator" content="Hexo 3.9.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta http-equiv="Content-Type" content="text/html" charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>使用 TensorFlow 來做簡單的手寫數字辨識 | TechBridge 技術共筆部落格</title>
  <meta name="description" content="TechBridge Weekly 技術週刊團隊是一群對用技術改變世界懷抱熱情的團隊。本技術共筆部落格初期專注於Web前後端、行動網路、機器人/物聯網、數據分析與產品設計等技術分享">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- google-site-verification -->
  <meta name="google-site-verification" content="WX_9sZlrIYOEpy8RR7zCoa7-pJk611zZt11BSBUcDVY">
  <link rel="stylesheet preload" type="text/css" href="/css/screen.css" as="style">
  <link rel="stylesheet preload" type="text/css" href="//fonts.googleapis.com/css?family=Noto+Serif:400,700,400italic|Open+Sans:700,400" as="style">

  <!-- Favicons -->
  <link rel="apple-touch-icon" href="/img/favicon.ico">
  <link rel="icon preload" href="/img/favicon.ico" as="image">

  
  
  <link rel="alternate" type="application/atom+xml" title="Atom 0.3" href="atom.xml"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  
  

  
</head>


<body class="post-template">

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><header class="site-head" >
    <div class="vertical">
        <div class="site-head-content inner">
             <a class="blog-logo" href="/"><img src="/img/logo-tb-500-500.png" alt="Blog Logo"/></a> 
            <h1 class="blog-title">TechBridge 技術共筆部落格</h1>
            <h2 class="blog-description">var topics = ['Web前後端', '行動網路', '機器人/物聯網', '數據分析', '產品設計', 'etc.']</h2>
            <div class="navbar-block">
                <span><a href="/">首頁</a></span> / <span><a href="/about/">關於我們</a></span> / <span><a href="http://weekly.techbridge.cc/" target="_blank">技術週刊</a></span> / <span><a href="https://www.facebook.com/techbridge.cc/" target="_blank">粉絲專頁</a></span> / <span><a href="/atom.xml" target="_blank">訂閱RSS </a></span>
                <br>
            </div>
        </div>
    </div>
</header>
  

<main class="content" role="main">
  <article class="post">
    <span class="post-meta">
      <time datetime="2018-01-27T23:09:17.000Z" itemprop="datePublished">
          2018-01-27
      </time>
    
    
    | 
    <a href='/tags/TensorFlow-Neural-Network/'>TensorFlow, Neural Network</a>
    
    
</span>

<meta name="generator" content="使用 TensorFlow 來做簡單的手寫數字辨識">
<meta name="og:title" content="使用 TensorFlow 來做簡單的手寫數字辨識">
<meta name="og:description" content="TechBridge Weekly 技術週刊團隊是一群對用技術改變世界懷抱熱情的團隊。本技術共筆部落格初期專注於Web前後端、行動網路、機器人/物聯網、數據分析與產品設計等技術分享。">
<meta name="og:type" content="website">
<meta name="og:image" content="/img/og-cover.png">

    <h1 class="post-title">使用 TensorFlow 來做簡單的手寫數字辨識</h1>
    <section class="post-content">
      <div class="fb-like" data-href="https://www.facebook.com/techbridge.cc" data-layout="button_count" data-action="like" data-size="large" data-show-faces="false" data-share="true"></div>   
      <hr>
      <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>相信大家都知道 TensorFlow 是可以用來建立跟訓練機器學習的模型，今天我們就來跑一個最簡單的 Neural Network，來辨識手寫數字，讓他吐出結果。有了這個程式之後，之後就可以再銜接其他的工具，例如讓機器人裝一個 camera，讀到 camera 的影像之後可以辨識數字，這樣就可以透過數字來對機器人下指令。或是可以再抽換辨識手寫數字的 node，改成辨識物體之類的。</p>
<p>接下來就讓我們開始吧。</p>
<h2 id="TensorFlow-辨識手寫數字"><a href="#TensorFlow-辨識手寫數字" class="headerlink" title="TensorFlow 辨識手寫數字"></a>TensorFlow 辨識手寫數字</h2><p>首先，我們可以直接參考現成的<a href="https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/neural_network_raw.py" target="_blank" rel="noopener">程式碼</a>，裡面兜出了一個 2 層的 Fully Connected Neural Network（也稱作 Multilayer Perceptron），裡面原本就有滿清楚的註解，讓大家易於理解：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">""" Neural Network.</span></span><br><span class="line"><span class="string">A 2-Hidden Layers Fully Connected Neural Network (a.k.a Multilayer Perceptron)</span></span><br><span class="line"><span class="string">implementation with TensorFlow. This example is using the MNIST database</span></span><br><span class="line"><span class="string">of handwritten digits (http://yann.lecun.com/exdb/mnist/).</span></span><br><span class="line"><span class="string">Links:</span></span><br><span class="line"><span class="string">    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).</span></span><br><span class="line"><span class="string">Author: Aymeric Damien</span></span><br><span class="line"><span class="string">Project: https://github.com/aymericdamien/TensorFlow-Examples/</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Import MNIST data</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"/tmp/data/"</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Parameters</span></span><br><span class="line">learning_rate = <span class="number">0.1</span></span><br><span class="line">num_steps = <span class="number">500</span></span><br><span class="line">batch_size = <span class="number">128</span></span><br><span class="line">display_step = <span class="number">100</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># Network Parameters</span></span><br><span class="line">n_hidden_1 = <span class="number">256</span> <span class="comment"># 1st layer number of neurons</span></span><br><span class="line">n_hidden_2 = <span class="number">256</span> <span class="comment"># 2nd layer number of neurons</span></span><br><span class="line">num_input = <span class="number">784</span> <span class="comment"># MNIST data input (img shape: 28*28)</span></span><br><span class="line">num_classes = <span class="number">10</span> <span class="comment"># MNIST total classes (0-9 digits)</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># tf Graph input</span></span><br><span class="line"><span class="comment"># place</span></span><br><span class="line">X = tf.placeholder(<span class="string">"float"</span>, [<span class="literal">None</span>, num_input])</span><br><span class="line">Y = tf.placeholder(<span class="string">"float"</span>, [<span class="literal">None</span>, num_classes])</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Store layers weight &amp; bias</span></span><br><span class="line">weights = &#123;</span><br><span class="line">    <span class="string">'h1'</span>: tf.Variable(tf.random_normal([num_input, n_hidden_1])),</span><br><span class="line">    <span class="string">'h2'</span>: tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),</span><br><span class="line">    <span class="string">'out'</span>: tf.Variable(tf.random_normal([n_hidden_2, num_classes]))</span><br><span class="line">&#125;</span><br><span class="line">biases = &#123;</span><br><span class="line">    <span class="string">'b1'</span>: tf.Variable(tf.random_normal([n_hidden_1])),</span><br><span class="line">    <span class="string">'b2'</span>: tf.Variable(tf.random_normal([n_hidden_2])),</span><br><span class="line">    <span class="string">'out'</span>: tf.Variable(tf.random_normal([num_classes]))</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="comment"># Create model</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">neural_net</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="comment"># Hidden fully connected layer with 256 neurons</span></span><br><span class="line">    layer_1 = tf.add(tf.matmul(x, weights[<span class="string">'h1'</span>]), biases[<span class="string">'b1'</span>])</span><br><span class="line">    <span class="comment"># Hidden fully connected layer with 256 neurons</span></span><br><span class="line">    layer_2 = tf.add(tf.matmul(layer_1, weights[<span class="string">'h2'</span>]), biases[<span class="string">'b2'</span>])</span><br><span class="line">    <span class="comment"># Output fully connected layer with a neuron for each class</span></span><br><span class="line">    out_layer = tf.matmul(layer_2, weights[<span class="string">'out'</span>]) + biases[<span class="string">'out'</span>]</span><br><span class="line">    <span class="keyword">return</span> out_layer</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Construct model</span></span><br><span class="line">logits = neural_net(X)</span><br><span class="line">prediction = tf.nn.softmax(logits)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Define loss and optimizer</span></span><br><span class="line">loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(</span><br><span class="line">    logits=logits, labels=Y))</span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)</span><br><span class="line">train_op = optimizer.minimize(loss_op)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Evaluate model</span></span><br><span class="line">correct_pred = tf.equal(tf.argmax(prediction, <span class="number">1</span>), tf.argmax(Y, <span class="number">1</span>))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Initialize the variables (i.e. assign their default value)</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Start training</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># Run the initializer</span></span><br><span class="line">    sess.run(init)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">1</span>, num_steps+<span class="number">1</span>):</span><br><span class="line">        batch_x, batch_y = mnist.train.next_batch(batch_size)</span><br><span class="line">        <span class="comment"># Run optimization op (backprop)</span></span><br><span class="line">        sess.run(train_op, feed_dict=&#123;X: batch_x, Y: batch_y&#125;)</span><br><span class="line">        <span class="keyword">if</span> step % display_step == <span class="number">0</span> <span class="keyword">or</span> step == <span class="number">1</span>:</span><br><span class="line">            <span class="comment"># Calculate batch loss and accuracy</span></span><br><span class="line">            loss, acc = sess.run([loss_op, accuracy], feed_dict=&#123;X: batch_x,</span><br><span class="line">                                                                 Y: batch_y&#125;)</span><br><span class="line">            print(<span class="string">"Step "</span> + str(step) + <span class="string">", Minibatch Loss= "</span> + \</span><br><span class="line">                  <span class="string">"&#123;:.4f&#125;"</span>.format(loss) + <span class="string">", Training Accuracy= "</span> + \</span><br><span class="line">                  <span class="string">"&#123;:.3f&#125;"</span>.format(acc))</span><br><span class="line"> </span><br><span class="line">    print(<span class="string">"Optimization Finished!"</span>)</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># Calculate accuracy for MNIST test images</span></span><br><span class="line">    print(<span class="string">"Testing Accuracy:"</span>, \</span><br><span class="line">        sess.run(accuracy, feed_dict=&#123;X: mnist.test.images,</span><br><span class="line">                                      Y: mnist.test.labels&#125;))</span><br></pre></td></tr></table></figure>
<p>執行這個程式之後，你應該會看到以下的結果，表示功能正常，可以拿來辨識手寫數字的 dataset：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">ros@ros-K401UB:~/code/standalone/tensorflow$ python3.4 simple_nn.py </span><br><span class="line">Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.</span><br><span class="line">Extracting /tmp/data/train-images-idx3-ubyte.gz</span><br><span class="line">Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.</span><br><span class="line">Extracting /tmp/data/train-labels-idx1-ubyte.gz</span><br><span class="line">Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.</span><br><span class="line">Extracting /tmp/data/t10k-images-idx3-ubyte.gz</span><br><span class="line">Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.</span><br><span class="line">Extracting /tmp/data/t10k-labels-idx1-ubyte.gz</span><br><span class="line">2018-01-27 13:10:45.868367: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA</span><br><span class="line">Step 1, Minibatch Loss= 12711.9502, Training Accuracy= 0.305</span><br><span class="line">Step 100, Minibatch Loss= 473.9966, Training Accuracy= 0.852</span><br><span class="line">Step 200, Minibatch Loss= 67.3683, Training Accuracy= 0.938</span><br><span class="line">Step 300, Minibatch Loss= 102.2178, Training Accuracy= 0.883</span><br><span class="line">Step 400, Minibatch Loss= 43.7579, Training Accuracy= 0.914</span><br><span class="line">Step 500, Minibatch Loss= 49.5792, Training Accuracy= 0.820</span><br><span class="line">Optimization Finished!</span><br><span class="line">Testing Accuracy: 0.8672</span><br></pre></td></tr></table></figure>
<p>但是，上面這個範例跑起來有點空虛，因為只是跑了一個 dataset，但我們是希望用來辨識一張圖片。</p>
<h2 id="儲存可以辨識手寫數字的-Model"><a href="#儲存可以辨識手寫數字的-Model" class="headerlink" title="儲存可以辨識手寫數字的 Model"></a>儲存可以辨識手寫數字的 Model</h2><p>雖然要訓練這個範例很簡單，但我們不希望每次啟動程式時都重新訓練一次，所以我們希望可以將訓練完的 model 儲存下來，我們主要可以參考這個<a href="https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/4_Utils/save_restore_model.py" target="_blank" rel="noopener">範例程式碼</a>，然後把儲存 model 需要用到的幾個函式放到我們上面的範例中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">""" Neural Network.</span></span><br><span class="line"><span class="string">A 2-Hidden Layers Fully Connected Neural Network (a.k.a Multilayer Perceptron)</span></span><br><span class="line"><span class="string">implementation with TensorFlow. This example is using the MNIST database</span></span><br><span class="line"><span class="string">of handwritten digits (http://yann.lecun.com/exdb/mnist/).</span></span><br><span class="line"><span class="string">Links:</span></span><br><span class="line"><span class="string">    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).</span></span><br><span class="line"><span class="string">Author: Aymeric Damien</span></span><br><span class="line"><span class="string">Project: https://github.com/aymericdamien/TensorFlow-Examples/</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Import MNIST data</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"/tmp/data/"</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Parameters</span></span><br><span class="line">learning_rate = <span class="number">0.1</span></span><br><span class="line">num_steps = <span class="number">500</span></span><br><span class="line">batch_size = <span class="number">128</span></span><br><span class="line">display_step = <span class="number">100</span></span><br><span class="line">model_path = <span class="string">"/tmp/model.ckpt"</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># Network Parameters</span></span><br><span class="line">n_hidden_1 = <span class="number">256</span> <span class="comment"># 1st layer number of neurons</span></span><br><span class="line">n_hidden_2 = <span class="number">256</span> <span class="comment"># 2nd layer number of neurons</span></span><br><span class="line">num_input = <span class="number">784</span> <span class="comment"># MNIST data input (img shape: 28*28)</span></span><br><span class="line">num_classes = <span class="number">10</span> <span class="comment"># MNIST total classes (0-9 digits)</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># tf Graph input</span></span><br><span class="line">X = tf.placeholder(<span class="string">"float"</span>, [<span class="literal">None</span>, num_input])</span><br><span class="line">Y = tf.placeholder(<span class="string">"float"</span>, [<span class="literal">None</span>, num_classes])</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Store layers weight &amp; bias</span></span><br><span class="line">weights = &#123;</span><br><span class="line">    <span class="string">'h1'</span>: tf.Variable(tf.random_normal([num_input, n_hidden_1])),</span><br><span class="line">    <span class="string">'h2'</span>: tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),</span><br><span class="line">    <span class="string">'out'</span>: tf.Variable(tf.random_normal([n_hidden_2, num_classes]))</span><br><span class="line">&#125;</span><br><span class="line">biases = &#123;</span><br><span class="line">    <span class="string">'b1'</span>: tf.Variable(tf.random_normal([n_hidden_1])),</span><br><span class="line">    <span class="string">'b2'</span>: tf.Variable(tf.random_normal([n_hidden_2])),</span><br><span class="line">    <span class="string">'out'</span>: tf.Variable(tf.random_normal([num_classes]))</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="comment"># Create model</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">neural_net</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="comment"># Hidden fully connected layer with 256 neurons</span></span><br><span class="line">    layer_1 = tf.add(tf.matmul(x, weights[<span class="string">'h1'</span>]), biases[<span class="string">'b1'</span>])</span><br><span class="line">    <span class="comment"># Hidden fully connected layer with 256 neurons</span></span><br><span class="line">    layer_2 = tf.add(tf.matmul(layer_1, weights[<span class="string">'h2'</span>]), biases[<span class="string">'b2'</span>])</span><br><span class="line">    <span class="comment"># Output fully connected layer with a neuron for each class</span></span><br><span class="line">    out_layer = tf.matmul(layer_2, weights[<span class="string">'out'</span>]) + biases[<span class="string">'out'</span>]</span><br><span class="line">    <span class="keyword">return</span> out_layer</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Construct model</span></span><br><span class="line">logits = neural_net(X)</span><br><span class="line">prediction = tf.nn.softmax(logits)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Define loss and optimizer</span></span><br><span class="line">loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(</span><br><span class="line">    logits=logits, labels=Y))</span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)</span><br><span class="line">train_op = optimizer.minimize(loss_op)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Evaluate model</span></span><br><span class="line">correct_pred = tf.equal(tf.argmax(prediction, <span class="number">1</span>), tf.argmax(Y, <span class="number">1</span>))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Initialize the variables (i.e. assign their default value)</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 'Saver' op to save and restore all the variables</span></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Start training</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># Run the initializer</span></span><br><span class="line">    sess.run(init)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">1</span>, num_steps+<span class="number">1</span>):</span><br><span class="line">        batch_x, batch_y = mnist.train.next_batch(batch_size)</span><br><span class="line">        <span class="comment"># Run optimization op (backprop)</span></span><br><span class="line">        sess.run(train_op, feed_dict=&#123;X: batch_x, Y: batch_y&#125;)</span><br><span class="line">        <span class="keyword">if</span> step % display_step == <span class="number">0</span> <span class="keyword">or</span> step == <span class="number">1</span>:</span><br><span class="line">            <span class="comment"># Calculate batch loss and accuracy</span></span><br><span class="line">            loss, acc = sess.run([loss_op, accuracy], feed_dict=&#123;X: batch_x,</span><br><span class="line">                                                                  Y: batch_y&#125;)</span><br><span class="line">            print(<span class="string">"Step "</span> + str(step) + <span class="string">", Minibatch Loss= "</span> + \</span><br><span class="line">                  <span class="string">"&#123;:.4f&#125;"</span>.format(loss) + <span class="string">", Training Accuracy= "</span> + \</span><br><span class="line">                  <span class="string">"&#123;:.3f&#125;"</span>.format(acc))</span><br><span class="line"> </span><br><span class="line">    print(<span class="string">"Optimization Finished!"</span>)</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># Save model weights to disk</span></span><br><span class="line">    save_path = saver.save(sess, model_path)</span><br><span class="line">    print(<span class="string">"Model saved in file: %s"</span> % save_path)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Running a test dataset by loading the model saved earlier</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># Run the initializer</span></span><br><span class="line">    sess.run(init)</span><br><span class="line"> </span><br><span class="line">    saver.restore(sess, model_path)</span><br><span class="line">    print(<span class="string">"Model restored from file: %s"</span> % save_path)</span><br><span class="line">     </span><br><span class="line">    <span class="comment"># Calculate accuracy for MNIST test images</span></span><br><span class="line">    print(<span class="string">"Testing Accuracy:"</span>, \</span><br><span class="line">    sess.run(accuracy, feed_dict=&#123;X: mnist.test.images,</span><br><span class="line">                                      Y: mnist.test.labels&#125;))</span><br></pre></td></tr></table></figure>
<p>把這個程式跑起來之後，你應該可以看到以下的輸出：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">ros@ros-K401UB:~/code/standalone/tensorflow$ python3.4 simple_nn_store.py </span><br><span class="line">^[[Z^[[ZExtracting /tmp/data/train-images-idx3-ubyte.gz</span><br><span class="line">Extracting /tmp/data/train-labels-idx1-ubyte.gz</span><br><span class="line">Extracting /tmp/data/t10k-images-idx3-ubyte.gz</span><br><span class="line">Extracting /tmp/data/t10k-labels-idx1-ubyte.gz</span><br><span class="line">2018-01-27 16:56:13.000020: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA</span><br><span class="line">Step 1, Minibatch Loss= 9857.0781, Training Accuracy= 0.320</span><br><span class="line">Step 100, Minibatch Loss= 320.8330, Training Accuracy= 0.859</span><br><span class="line">Step 200, Minibatch Loss= 121.9466, Training Accuracy= 0.805</span><br><span class="line">Step 300, Minibatch Loss= 55.0800, Training Accuracy= 0.891</span><br><span class="line">Step 400, Minibatch Loss= 89.7953, Training Accuracy= 0.828</span><br><span class="line">Step 500, Minibatch Loss= 52.5457, Training Accuracy= 0.836</span><br><span class="line">Optimization Finished!</span><br><span class="line">Model saved in file: /tmp/model.ckpt</span><br><span class="line">Model restored from file: /tmp/model.ckpt</span><br><span class="line">Testing Accuracy: 0.847</span><br></pre></td></tr></table></figure>
<h2 id="將辨識手寫數字的-Model-變成可以吃一張-28x28-的影像並輸出答案"><a href="#將辨識手寫數字的-Model-變成可以吃一張-28x28-的影像並輸出答案" class="headerlink" title="將辨識手寫數字的 Model 變成可以吃一張 28x28 的影像並輸出答案"></a>將辨識手寫數字的 Model 變成可以吃一張 28x28 的影像並輸出答案</h2><p>上面的兩步，我們已經把基本範例用起來，不過他還不太直覺，因為我們是希望讓手寫辨識的 node 可以吃進一張影像，然後吐出結果，所以在這一步我們要改寫一下。</p>
<p>一步一步來，首先我們可以將 training 的地方改成直接讀取 train 好的 model，然後把計算 accuracy 的地方改成直接輸出辨識的結果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"/tmp/data/"</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Parameters</span></span><br><span class="line">model_path = <span class="string">"/tmp/model.ckpt"</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># Network Parameters</span></span><br><span class="line">n_hidden_1 = <span class="number">256</span> <span class="comment"># 1st layer number of neurons</span></span><br><span class="line">n_hidden_2 = <span class="number">256</span> <span class="comment"># 2nd layer number of neurons</span></span><br><span class="line">num_input = <span class="number">784</span> <span class="comment"># MNIST data input (img shape: 28*28)</span></span><br><span class="line">num_classes = <span class="number">10</span> <span class="comment"># MNIST total classes (0-9 digits)</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># tf Graph input</span></span><br><span class="line">X = tf.placeholder(<span class="string">"float"</span>, [<span class="literal">None</span>, num_input])</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Store layers weight &amp; bias</span></span><br><span class="line">weights = &#123;</span><br><span class="line">    <span class="string">'h1'</span>: tf.Variable(tf.random_normal([num_input, n_hidden_1])),</span><br><span class="line">    <span class="string">'h2'</span>: tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),</span><br><span class="line">    <span class="string">'out'</span>: tf.Variable(tf.random_normal([n_hidden_2, num_classes]))</span><br><span class="line">&#125;</span><br><span class="line">biases = &#123;</span><br><span class="line">    <span class="string">'b1'</span>: tf.Variable(tf.random_normal([n_hidden_1])),</span><br><span class="line">    <span class="string">'b2'</span>: tf.Variable(tf.random_normal([n_hidden_2])),</span><br><span class="line">    <span class="string">'out'</span>: tf.Variable(tf.random_normal([num_classes]))</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Create model</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">neural_net</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="comment"># Hidden fully connected layer with 256 neurons</span></span><br><span class="line">    layer_1 = tf.add(tf.matmul(x, weights[<span class="string">'h1'</span>]), biases[<span class="string">'b1'</span>])</span><br><span class="line">    <span class="comment"># Hidden fully connected layer with 256 neurons</span></span><br><span class="line">    layer_2 = tf.add(tf.matmul(layer_1, weights[<span class="string">'h2'</span>]), biases[<span class="string">'b2'</span>])</span><br><span class="line">    <span class="comment"># Output fully connected layer with a neuron for each class</span></span><br><span class="line">    out_layer = tf.matmul(layer_2, weights[<span class="string">'out'</span>]) + biases[<span class="string">'out'</span>]</span><br><span class="line">    <span class="keyword">return</span> out_layer</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Construct model</span></span><br><span class="line">logits = neural_net(X)</span><br><span class="line">prediction = tf.nn.softmax(logits)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Evaluate model</span></span><br><span class="line"><span class="comment"># argmax returns the index with the largest value across axes of a tensor</span></span><br><span class="line">ans = tf.argmax(prediction, <span class="number">1</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Initialize the variables (i.e. assign their default value)</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 'Saver' op to save and restore all the variables</span></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Running a test dataset by loading the model saved earlier</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># Run the initializer</span></span><br><span class="line">    sess.run(init)</span><br><span class="line"> </span><br><span class="line">    saver.restore(sess, model_path)</span><br><span class="line">    print(<span class="string">"Model restored from file: %s"</span> % model_path)</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># Calculate accuracy for MNIST test images</span></span><br><span class="line">    print(<span class="string">"Answer:"</span>, sess.run(ans, feed_dict=&#123;X: mnist.test.images&#125;))</span><br></pre></td></tr></table></figure>
<p>跑出來之後，你應該會看到下列結果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ros@ros-K401UB:~/code/standalone/tensorflow$ python3.4 simple_nn_srv.py</span><br><span class="line">Extracting /tmp/data/train-images-idx3-ubyte.gz</span><br><span class="line">Extracting /tmp/data/train-labels-idx1-ubyte.gz</span><br><span class="line">Extracting /tmp/data/t10k-images-idx3-ubyte.gz</span><br><span class="line">Extracting /tmp/data/t10k-labels-idx1-ubyte.gz</span><br><span class="line">2018-01-27 20:06:24.861211: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA</span><br><span class="line">Model restored from file: /tmp/model.ckpt</span><br><span class="line">Answer: [7 2 1 ..., 4 5 6]</span><br></pre></td></tr></table></figure>
<p>然後，我們可以將他改成只吃一張影像，並輸出這張影像的辨識結果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">""" Neural Network.</span></span><br><span class="line"><span class="string">A 2-Hidden Layers Fully Connected Neural Network (a.k.a Multilayer Perceptron)</span></span><br><span class="line"><span class="string">implementation with TensorFlow. This example is using the MNIST database</span></span><br><span class="line"><span class="string">of handwritten digits (http://yann.lecun.com/exdb/mnist/).</span></span><br><span class="line"><span class="string">Links:</span></span><br><span class="line"><span class="string">    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).</span></span><br><span class="line"><span class="string">Author: Aymeric Damien</span></span><br><span class="line"><span class="string">Project: https://github.com/aymericdamien/TensorFlow-Examples/</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"/tmp/data/"</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Parameters</span></span><br><span class="line">model_path = <span class="string">"/tmp/model.ckpt"</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># Network Parameters</span></span><br><span class="line">n_hidden_1 = <span class="number">256</span> <span class="comment"># 1st layer number of neurons</span></span><br><span class="line">n_hidden_2 = <span class="number">256</span> <span class="comment"># 2nd layer number of neurons</span></span><br><span class="line">num_input = <span class="number">784</span> <span class="comment"># MNIST data input (img shape: 28*28)</span></span><br><span class="line">num_classes = <span class="number">10</span> <span class="comment"># MNIST total classes (0-9 digits)</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># tf Graph input</span></span><br><span class="line">X = tf.placeholder(<span class="string">"float"</span>, [<span class="literal">None</span>, num_input])</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Store layers weight &amp; bias</span></span><br><span class="line">weights = &#123;</span><br><span class="line">    <span class="string">'h1'</span>: tf.Variable(tf.random_normal([num_input, n_hidden_1])),</span><br><span class="line">    <span class="string">'h2'</span>: tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),</span><br><span class="line">    <span class="string">'out'</span>: tf.Variable(tf.random_normal([n_hidden_2, num_classes]))</span><br><span class="line">&#125;</span><br><span class="line">biases = &#123;</span><br><span class="line">    <span class="string">'b1'</span>: tf.Variable(tf.random_normal([n_hidden_1])),</span><br><span class="line">    <span class="string">'b2'</span>: tf.Variable(tf.random_normal([n_hidden_2])),</span><br><span class="line">    <span class="string">'out'</span>: tf.Variable(tf.random_normal([num_classes]))</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Create model</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">neural_net</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="comment"># Hidden fully connected layer with 256 neurons</span></span><br><span class="line">    layer_1 = tf.add(tf.matmul(x, weights[<span class="string">'h1'</span>]), biases[<span class="string">'b1'</span>])</span><br><span class="line">    <span class="comment"># Hidden fully connected layer with 256 neurons</span></span><br><span class="line">    layer_2 = tf.add(tf.matmul(layer_1, weights[<span class="string">'h2'</span>]), biases[<span class="string">'b2'</span>])</span><br><span class="line">    <span class="comment"># Output fully connected layer with a neuron for each class</span></span><br><span class="line">    out_layer = tf.matmul(layer_2, weights[<span class="string">'out'</span>]) + biases[<span class="string">'out'</span>]</span><br><span class="line">    <span class="keyword">return</span> out_layer</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Construct model</span></span><br><span class="line">logits = neural_net(X)</span><br><span class="line">prediction = tf.nn.softmax(logits)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Evaluate model</span></span><br><span class="line"><span class="comment"># argmax returns the index with the largest value across axes of a tensor</span></span><br><span class="line">ans = tf.argmax(prediction, <span class="number">1</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Initialize the variables (i.e. assign their default value)</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 'Saver' op to save and restore all the variables</span></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Show image that we want to predict</span></span><br><span class="line">plt.imshow(mnist.test.images[<span class="number">0</span>].reshape((<span class="number">28</span>, <span class="number">28</span>)))</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Running a test dataset by loading the model saved earlier</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># Run the initializer</span></span><br><span class="line">    sess.run(init)</span><br><span class="line"> </span><br><span class="line">    saver.restore(sess, model_path)</span><br><span class="line">    print(<span class="string">"Model restored from file: %s"</span> % model_path)</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># Calculate the answer for the image</span></span><br><span class="line">    print(<span class="string">"Answer:"</span>, sess.run(ans, feed_dict=&#123;X: mnist.test.images[<span class="number">0</span>:<span class="number">1</span>]&#125;))</span><br></pre></td></tr></table></figure>
<p>跑起來之後，你應該會先看到這個圖片的輸出：</p>
<p><img src="/img/pojenlai/mnist_seven.png" alt="minst_img"></p>
<p>然後會看到下列的命令列輸出：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ros@ros-K401UB:~/code/standalone/tensorflow$ python3.4 simple_nn_srv.py</span><br><span class="line">Extracting /tmp/data/train-images-idx3-ubyte.gz</span><br><span class="line">Extracting /tmp/data/train-labels-idx1-ubyte.gz</span><br><span class="line">Extracting /tmp/data/t10k-images-idx3-ubyte.gz</span><br><span class="line">Extracting /tmp/data/t10k-labels-idx1-ubyte.gz</span><br><span class="line">2018-01-27 23:08:35.638018: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA</span><br><span class="line">Model restored from file: /tmp/model.ckpt</span><br><span class="line">Answer: [7]</span><br></pre></td></tr></table></figure>
<p>可以看到自己的 model 成功辨識數字了!</p>
<h2 id="總結"><a href="#總結" class="headerlink" title="總結"></a>總結</h2><p>今天我們一起使用 TensorFlow 了一個可以辨識手寫數字的程式，其實這個範例可以用來做很多事情，例如你可以將辨識手寫數字的程式跟 ROS 串起來，變成可以辨識手寫數字的 node（只需要再串接 ROS），然後建立一個 service ，就可以讓其他人拿圖片來跟這個 node 要求辨識結果。或是將 node 裡面的功能和訊息格式修改一下，就可以做到物體辨識。之後有機會再一起來實作。</p>
<p>關於作者：<br><a href="https://pojenlai.wordpress.com/" target="_blank" rel="noopener">@pojenlai</a> 演算法工程師，對機器人跟電腦視覺有少許研究，最近在學習<a href="https://buzzorange.com/techorange/2017/07/10/elon-musk-first-principle/" target="_blank" rel="noopener">看清事物的本質與改進自己的觀念</a></p>
  
      <div>喜歡我們的文章嗎？歡迎分享按讚給予我們支持和鼓勵！</div>
      <div class="fb-like" data-href="https://blog.techbridge.cc/2018/01/27/tensorflow-mnist/index.html" data-layout="button_count" data-action="like" data-size="large" data-show-faces="false" data-share="true"></div>
      <br>
      <br>
      <div class="fb-page" data-href="https://www.facebook.com/techbridge.cc" data-small-header="false" data-adapt-container-width="true" data-hide-cover="false" data-show-facepile="true"><blockquote cite="https://www.facebook.com/techbridge.cc" class="fb-xfbml-parse-ignore"><a href="https://www.facebook.com/techbridge.cc">TechBridge 技術日報</a></blockquote></div>
      <br>
    </section>
    <br>
    <hr>
    <div>
      <h4>訂閱 TechBridge Weekly 技術週刊，每週發送最精華的技術開發、產品設計的資訊給您</h4>
      <form class="form-control" method="post" action="https://goodbits.io/e/cab8a418-6b70-48d6-97ea-b5f0ef34b22c" target="_blank">
        <input class="form-control" type="text" name="first_name" placeholder="First Name"></input>
        <input class="form-control" type="text" name="last_name" placeholder="Last Name"></input>
        <div>
          <input class="form-control" type="text" name="email" placeholder="Email"></input>
        </div>
        <br>
        <div>
          <button class="form-control btn subscribe-btn" type="submit">馬上訂閱技術週刊</button>
        </div>
        <br>
        <label for="">PS. 我們討厭垃圾信，所以我們只提供有價值的內容給您 :)</label>
      </form>
    </div>
    <footer class="post-footer">
      <section class="author">
    <h4>TechBridge Weekly 技術週刊編輯團隊</h4>
    <p>TechBridge Weekly 技術週刊團隊是一群對用技術改變世界懷抱熱情的團隊。本技術共筆部落格初期專注於Web前後端、行動網路、機器人/物聯網、資料科學與產品設計等技術分享。This is TechBridge Weekly Team Tech Blog, which focus on web, mobile, robotics, IoT, Data Science technology sharing.</p>
    <span><a href="/2016/03/19/about/">關於我們</a></span> / <span><a href="https://www.techbridge.cc/" target="_blank">技術日報</a></span> / <span><a href="http://weekly.techbridge.cc/" target="_blank">技術週刊</a></span> / <span><a href="https://www.facebook.com/techbridge.cc/" target="_blank">粉絲專頁</a></span> / <span><a href="/atom.xml" target="_blank">訂閱RSS </a></span>   
	<div class="fb-like" data-href="https://www.facebook.com/techbridge.cc" data-layout="button_count" data-size="large" data-action="like" data-show-faces="false" data-share="true"></div>    
</section>
      <section class="share">
    <h4>Share this post</h4>
    <a class="icon-twitter" href="http://twitter.com/share?url=https://blog.techbridge.cc/2018/01/27/tensorflow-mnist/"
       onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
        <span class="hidden">Twitter</span>
    </a>
    <a class="icon-facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://blog.techbridge.cc/2018/01/27/tensorflow-mnist/"
       onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
        <span class="hidden">Facebook</span>
    </a>
    <a class="icon-google-plus" href="https://plus.google.com/share?url=https://blog.techbridge.cc/2018/01/27/tensorflow-mnist/"
       onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
        <span class="hidden">Google+</span>
    </a>
    <iframe src="https://ghbtns.com/github-btn.html?user=TechBridgeHQ&repo=blog-starter-kit&type=star&count=true" frameborder="0" scrolling="0" width="170px" height="20px"></iframe>      
</section>
    </footer>
    <br>
  </article>
  <nav class="pagination" role="pagination">
    <h2>更多優質技術文章</h2>
    
    <a class="newer-posts" href="/2018/02/03/github-classroom-and-travis-ci/">
        ← 利用 Github Classroom 加 Travis CI 打造改作業系統
    </a>
    
    <span class="page-number">•</span>
    
    <a class="older-posts" href="/2018/01/17/learning-programming-and-coding-with-python-git-and-github-tutorial/">
        Git 與 Github 版本控制基本指令與操作入門教學 →
    </a>
    
</nav>
  <div id="comment" class="comments-area">
    <h1 class="title"><a href="#disqus_comments" name="disqus_comments">留言討論</a></h1>

    
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>
    
</div>
</main>


  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-75308642-1', 'auto');
  ga('send', 'pageview');

</script>
<footer class="site-footer">
  
  <a class="subscribe icon-feed" href="/atom.xml"><span class="tooltip">Subscribe!</span></a>
  
  <div class="inner">
     <section class="copyright">All content copyright <a href="/">TechBridge 技術共筆部落格</a> &copy; 2017 &bull; All rights reserved.</section>
  </div>
</footer>

  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script type="text/javascript" src="/js/jquery.fitvids.js"></script>
<script type="text/javascript" src="/js/index.js"></script>


<script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', '[object Object]']);
    _gaq.push(['_trackPageview']);

    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
</script>


<script type="text/javascript">
    var disqus_shortname = 'techbridgeweekly';

    (function(){
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.4/dist/medium-zoom.min.js"></script>
<script>
// NodeList
mediumZoom(document.querySelectorAll('img'));
</script>
  <div id="fb-root"></div>
	<script>(function(d, s, id) {
	  var js, fjs = d.getElementsByTagName(s)[0];
	  if (d.getElementById(id)) return;
	  js = d.createElement(s); js.id = id;
	  js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&version=v2.5";
	  fjs.parentNode.insertBefore(js, fjs);
	}(document, 'script', 'facebook-jssdk'));</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>
